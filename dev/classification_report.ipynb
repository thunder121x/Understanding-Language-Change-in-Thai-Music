{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfaa5f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca4331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tag_train_split_100000/tag_train_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "528562d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clean_lyrics</th>\n",
       "      <th>year</th>\n",
       "      <th>song_era</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368884</td>\n",
       "      <td>before you go can we just talk a moment we sho...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2337301</td>\n",
       "      <td>verse: david has daringly dented his death - t...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3153329</td>\n",
       "      <td>: see there is something about you that keeps ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3501728</td>\n",
       "      <td>i sit her waiting thinking only of you all nig...</td>\n",
       "      <td>1984</td>\n",
       "      <td>1980s</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6076431</td>\n",
       "      <td>belladonna  who are you how did you get in her...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467165</th>\n",
       "      <td>4154755</td>\n",
       "      <td>coinstar coinstar  i went to the coinstar to s...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467166</th>\n",
       "      <td>7052078</td>\n",
       "      <td>let the bandplay  yessir    no nine to five bo...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020s</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467167</th>\n",
       "      <td>3186330</td>\n",
       "      <td>came home late last evening feeling mellow as ...</td>\n",
       "      <td>1978</td>\n",
       "      <td>1970s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467168</th>\n",
       "      <td>4693947</td>\n",
       "      <td>lonely soul by romeo ryu reyes  i remember the...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467169</th>\n",
       "      <td>2265732</td>\n",
       "      <td>wishin' i could pick you up whishin' that you ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467170 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       clean_lyrics  year  \\\n",
       "0       1368884  before you go can we just talk a moment we sho...  2000   \n",
       "1       2337301  verse: david has daringly dented his death - t...  2014   \n",
       "2       3153329  : see there is something about you that keeps ...  2017   \n",
       "3       3501728  i sit her waiting thinking only of you all nig...  1984   \n",
       "4       6076431  belladonna  who are you how did you get in her...  2020   \n",
       "...         ...                                                ...   ...   \n",
       "467165  4154755  coinstar coinstar  i went to the coinstar to s...  2018   \n",
       "467166  7052078  let the bandplay  yessir    no nine to five bo...  2021   \n",
       "467167  3186330  came home late last evening feeling mellow as ...  1978   \n",
       "467168  4693947  lonely soul by romeo ryu reyes  i remember the...  2018   \n",
       "467169  2265732  wishin' i could pick you up whishin' that you ...  2015   \n",
       "\n",
       "       song_era   tag  \n",
       "0         2000s    rb  \n",
       "1         2010s   rap  \n",
       "2         2010s    rb  \n",
       "3         1980s  rock  \n",
       "4         2020s    rb  \n",
       "...         ...   ...  \n",
       "467165    2010s    rb  \n",
       "467166    2020s   rap  \n",
       "467167    1970s    rb  \n",
       "467168    2010s    rb  \n",
       "467169    2010s    rb  \n",
       "\n",
       "[467170 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9281885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"[,\\.!?]\", \"\", text)\n",
    "    text = re.sub(r\"\\[.*?\\]\", \" \", text)\n",
    "    text = re.sub(r\"\\w*\\d\\w*\", \" \", text)\n",
    "    text = re.sub(r\"[()]\", \" \", text)\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ed3bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "binary_results = joblib.load(\"tag_prediction_model/log_reg_binary_model.pkl\")\n",
    "multi_class_results = joblib.load(\"tag_prediction_model/log_reg_multi_class_model.pkl\")\n",
    "multi_class_vectorizers = joblib.load(\"tag_prediction_model/log_reg_multi_class_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4db2712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class model prediction: pop\n",
      "Scores (Multi-class): {'country': np.float64(0.19509428758929764), 'pop': np.float64(0.6934681500055102), 'rap': np.float64(0.005357231031915173), 'rb': np.float64(0.14264188155953247), 'rock': np.float64(0.6461613546200907)}\n",
      "Binary model prediction: country\n",
      "Scores (Binary): {'country': np.float64(0.7363434024429886), 'pop': np.float64(0.40000921787227045), 'rap': np.float64(0.035791506030793736), 'rb': np.float64(0.1528520933419467), 'rock': np.float64(0.31308511015325274)}\n"
     ]
    }
   ],
   "source": [
    "def safe_predict_proba(model, X):\n",
    "    \"\"\"à¹ƒà¸Šà¹‰ predict_proba à¸«à¸£à¸·à¸­ decision_function à¹à¸šà¸š sigmoid à¸ªà¸³à¸«à¸£à¸±à¸š binary/logistic\"\"\"\n",
    "    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š feature size à¸à¹ˆà¸­à¸™\n",
    "    if X.shape[1] != model.n_features_in_:\n",
    "        # à¹€à¸•à¸´à¸¡ 0 à¹ƒà¸«à¹‰ feature à¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸² model expects\n",
    "        X_new = np.zeros((X.shape[0], model.n_features_in_))\n",
    "        X_new[:, :X.shape[1]] = X.toarray()\n",
    "        X = X_new\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[0][1]  # probability à¸‚à¸­à¸‡ class '1'\n",
    "    else:\n",
    "        score = model.decision_function(X)[0]\n",
    "        return 1 / (1 + np.exp(-score))\n",
    "\n",
    "def predict_genre(text, weight_multi=0.6, weight_bin=0.4):\n",
    "    text_cleaned = clean_text(text)\n",
    "    scores_multi = {}\n",
    "    scores_bin = {}\n",
    "\n",
    "    for g in binary_results:\n",
    "        # Binary\n",
    "        vect_bin = binary_results[g][\"vectorizer\"]\n",
    "        model_bin = binary_results[g][\"model\"]\n",
    "        x_bin = vect_bin.transform([text_cleaned])\n",
    "        prob_bin = safe_predict_proba(model_bin, x_bin)\n",
    "        scores_bin[g] = prob_bin\n",
    "\n",
    "        # Multi-class\n",
    "        vect_multi = multi_class_vectorizers[g]\n",
    "        model_multi = multi_class_results[g]\n",
    "        x_bin = vect_multi.transform([text_cleaned])\n",
    "        prob_multi = safe_predict_proba(model_multi, x_bin)\n",
    "        scores_multi[g] = prob_multi\n",
    "\n",
    "\n",
    "    # genre à¸—à¸µà¹ˆà¸„à¸°à¹à¸™à¸™à¸ªà¸¹à¸‡à¸ªà¸¸à¸”\n",
    "    pred_multi = max(scores_multi, key=scores_multi.get)\n",
    "    pred_bin = max(scores_bin, key=scores_bin.get)\n",
    "\n",
    "    return {\n",
    "        \"multi_class\": pred_multi,\n",
    "        \"binary\": pred_bin,\n",
    "        \"scores_multi\": scores_multi,\n",
    "        \"scores_bin\": scores_bin,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™\n",
    "# -----------------------------\n",
    "lyrics = \"\"\"\n",
    "Made a meal and threw it up on Sunday\n",
    "I've got a lot of things to learn\n",
    "Said I would and I'll be leaving one day\n",
    "Before my heart starts to burn\n",
    "\n",
    "So what's the matter with you?\n",
    "Sing me something new\n",
    "Don't you know the cold and wind and rain don't know\n",
    "They only seem to come and go away\n",
    "\n",
    "Times are hard when things have got no meaning\n",
    "I've found a key upon the floor\n",
    "Maybe you and I will not believe in\n",
    "The things we find behind the door\n",
    "\n",
    "So what's the matter with you?\n",
    "Sing me something new\n",
    "Don't you know the cold and wind and rain don't know\n",
    "They only seem to come and go away\n",
    "\n",
    "Stand by me, nobody knows the way it's gonna be\n",
    "Stand by me, nobody knows the way it's gonna be\n",
    "Stand by me, nobody knows the way it's gonna be\n",
    "Stand by me, nobody knows\n",
    "Yeah, nobody knows, the way it's gonna be\n",
    "\n",
    "If you're leaving will you take me with you?\n",
    "I'm tired of talking on my phone\n",
    "There is one thing I can never give you\n",
    "My heart will never be your home\n",
    "\n",
    "So what's the matter with you?\n",
    "Sing me something new\n",
    "Don't you know the cold and wind and rain don't know\n",
    "They only seem to come and go away\n",
    "\"\"\"\n",
    "predictions = predict_genre(lyrics)\n",
    "\n",
    "print(\"Multi-class model prediction:\", predictions[\"multi_class\"])\n",
    "print(\"Scores (Multi-class):\", predictions[\"scores_multi\"])\n",
    "print(\"Binary model prediction:\", predictions[\"binary\"])\n",
    "print(\"Scores (Binary):\", predictions[\"scores_bin\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06c46292",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# APPLY TO YOUR DF\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m df = \u001b[43mapply_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mapply_predictions\u001b[39m\u001b[34m(df, text_col)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Loop through dataframe\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, text \u001b[38;5;129;01min\u001b[39;00m df[text_col].items():\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     result = \u001b[43mpredict_genre\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Set predictions\u001b[39;00m\n\u001b[32m     30\u001b[39m     df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mpred_bin\u001b[39m\u001b[33m\"\u001b[39m] = result[\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mpredict_genre\u001b[39m\u001b[34m(text, weight_multi, weight_bin)\u001b[39m\n\u001b[32m     29\u001b[39m vect_multi = multi_class_vectorizers[g]\n\u001b[32m     30\u001b[39m model_multi = multi_class_results[g]\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m x_bin = \u001b[43mvect_multi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_cleaned\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m prob_multi = safe_predict_proba(model_multi, x_bin)\n\u001b[32m     33\u001b[39m scores_multi[g] = prob_multi\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:2129\u001b[39m, in \u001b[36mTfidfVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[32m   2113\u001b[39m \n\u001b[32m   2114\u001b[39m \u001b[33;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2125\u001b[39m \u001b[33;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[32m   2126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2127\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg=\u001b[33m\"\u001b[39m\u001b[33mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2129\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfidf.transform(X, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1422\u001b[39m, in \u001b[36mCountVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   1419\u001b[39m \u001b[38;5;28mself\u001b[39m._check_vocabulary()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m _, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_vocab\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1424\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1264\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[32m   1263\u001b[39m     feature_counter = {}\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1265\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1266\u001b[39m             feature_idx = vocabulary[feature]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:106\u001b[39m, in \u001b[36m_analyze\u001b[39m\u001b[34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[39m\n\u001b[32m    104\u001b[39m     doc = preprocessor(doc)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     doc = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------\n",
    "# APPLY TO DATAFRAME\n",
    "# -------------------------------------\n",
    "def apply_predictions(df, text_col=\"clean_lyrics\"):\n",
    "    # Auto-detect genre keys from loaded models\n",
    "    genres = list(binary_results.keys())   # example: ['pop', 'rock', 'rap', 'rb', 'country']\n",
    "\n",
    "    # Prepare empty columns\n",
    "    df[\"pred_bin\"] = None\n",
    "    df[\"pred_multi\"] = None\n",
    "\n",
    "    for g in genres:\n",
    "        df[f\"conf_bin_{g}\"] = None\n",
    "        df[f\"conf_multi_{g}\"] = None\n",
    "\n",
    "    # Loop through dataframe\n",
    "    for idx, text in df[text_col].items():\n",
    "        result = predict_genre(text)\n",
    "\n",
    "        # Set predictions\n",
    "        df.at[idx, \"pred_bin\"] = result[\"binary\"]\n",
    "        df.at[idx, \"pred_multi\"] = result[\"multi_class\"]\n",
    "\n",
    "        # Save binary probabilities\n",
    "        for g, v in result[\"scores_bin\"].items():\n",
    "            df.at[idx, f\"conf_bin_{g}\"] = float(v)\n",
    "\n",
    "        # Save multi-class probabilities\n",
    "        for g, v in result[\"scores_multi\"].items():\n",
    "            df.at[idx, f\"conf_multi_{g}\"] = float(v)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# APPLY TO YOUR DF\n",
    "# ----------------------------\n",
    "df = apply_predictions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5342c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clean_lyrics</th>\n",
       "      <th>year</th>\n",
       "      <th>song_era</th>\n",
       "      <th>tag</th>\n",
       "      <th>pred_bin</th>\n",
       "      <th>pred_multi</th>\n",
       "      <th>conf_bin_country</th>\n",
       "      <th>conf_multi_country</th>\n",
       "      <th>conf_bin_pop</th>\n",
       "      <th>conf_multi_pop</th>\n",
       "      <th>conf_bin_rap</th>\n",
       "      <th>conf_multi_rap</th>\n",
       "      <th>conf_bin_rb</th>\n",
       "      <th>conf_multi_rb</th>\n",
       "      <th>conf_bin_rock</th>\n",
       "      <th>conf_multi_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3243956</td>\n",
       "      <td>from a young child they were groomed a silver ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.190897</td>\n",
       "      <td>0.149482</td>\n",
       "      <td>0.408375</td>\n",
       "      <td>0.398963</td>\n",
       "      <td>0.618757</td>\n",
       "      <td>0.546467</td>\n",
       "      <td>0.072935</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.444018</td>\n",
       "      <td>0.606285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133218</td>\n",
       "      <td>fly fly away from troubles from pain from ever...</td>\n",
       "      <td>2013</td>\n",
       "      <td>2010s</td>\n",
       "      <td>misc</td>\n",
       "      <td>rock</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.40449</td>\n",
       "      <td>0.369744</td>\n",
       "      <td>0.563257</td>\n",
       "      <td>0.412386</td>\n",
       "      <td>0.131492</td>\n",
       "      <td>0.05283</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>0.788672</td>\n",
       "      <td>0.423378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4776446</td>\n",
       "      <td>night and day you are the one day and night wh...</td>\n",
       "      <td>1976</td>\n",
       "      <td>1970s</td>\n",
       "      <td>rb</td>\n",
       "      <td>pop</td>\n",
       "      <td>rb</td>\n",
       "      <td>0.647109</td>\n",
       "      <td>0.279069</td>\n",
       "      <td>0.701033</td>\n",
       "      <td>0.591166</td>\n",
       "      <td>0.140559</td>\n",
       "      <td>0.02307</td>\n",
       "      <td>0.493494</td>\n",
       "      <td>0.730702</td>\n",
       "      <td>0.552208</td>\n",
       "      <td>0.399072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3018973</td>\n",
       "      <td>the word on the street is that you're nothing ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rock</td>\n",
       "      <td>rb</td>\n",
       "      <td>rb</td>\n",
       "      <td>0.12651</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.440449</td>\n",
       "      <td>0.295926</td>\n",
       "      <td>0.34544</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>0.540133</td>\n",
       "      <td>0.879046</td>\n",
       "      <td>0.454184</td>\n",
       "      <td>0.262347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3506859</td>\n",
       "      <td>honey i know you wanted me to be a jerk i know...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010s</td>\n",
       "      <td>country</td>\n",
       "      <td>pop</td>\n",
       "      <td>country</td>\n",
       "      <td>0.457873</td>\n",
       "      <td>0.56247</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.419094</td>\n",
       "      <td>0.362932</td>\n",
       "      <td>0.078012</td>\n",
       "      <td>0.317433</td>\n",
       "      <td>0.09485</td>\n",
       "      <td>0.288224</td>\n",
       "      <td>0.371424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57671</th>\n",
       "      <td>3510901</td>\n",
       "      <td>king of the ocean like nep making that girl so...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.00856</td>\n",
       "      <td>0.097584</td>\n",
       "      <td>0.771129</td>\n",
       "      <td>0.946513</td>\n",
       "      <td>0.953579</td>\n",
       "      <td>0.181817</td>\n",
       "      <td>0.063754</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.019171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57672</th>\n",
       "      <td>4233574</td>\n",
       "      <td>intro   you you were the one you you were the ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rb</td>\n",
       "      <td>rb</td>\n",
       "      <td>rb</td>\n",
       "      <td>0.114652</td>\n",
       "      <td>0.071239</td>\n",
       "      <td>0.232559</td>\n",
       "      <td>0.705958</td>\n",
       "      <td>0.554192</td>\n",
       "      <td>0.130881</td>\n",
       "      <td>0.578938</td>\n",
       "      <td>0.751298</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.123574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57673</th>\n",
       "      <td>365387</td>\n",
       "      <td>now i realize weâ€™ve been at this for some time...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2010s</td>\n",
       "      <td>misc</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.109686</td>\n",
       "      <td>0.067209</td>\n",
       "      <td>0.268143</td>\n",
       "      <td>0.67046</td>\n",
       "      <td>0.61364</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0.214917</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.46163</td>\n",
       "      <td>0.220678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57674</th>\n",
       "      <td>3302658</td>\n",
       "      <td>brennan jackson back at it again    it's lit i...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2010s</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>0.469893</td>\n",
       "      <td>0.049385</td>\n",
       "      <td>0.356064</td>\n",
       "      <td>0.730913</td>\n",
       "      <td>0.811409</td>\n",
       "      <td>0.791271</td>\n",
       "      <td>0.295346</td>\n",
       "      <td>0.50523</td>\n",
       "      <td>0.109829</td>\n",
       "      <td>0.032338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57675</th>\n",
       "      <td>1388972</td>\n",
       "      <td>there might be a question that you ask before ...</td>\n",
       "      <td>1987</td>\n",
       "      <td>1980s</td>\n",
       "      <td>pop</td>\n",
       "      <td>rb</td>\n",
       "      <td>rb</td>\n",
       "      <td>0.524606</td>\n",
       "      <td>0.191578</td>\n",
       "      <td>0.488127</td>\n",
       "      <td>0.600158</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.049851</td>\n",
       "      <td>0.616564</td>\n",
       "      <td>0.810046</td>\n",
       "      <td>0.292769</td>\n",
       "      <td>0.304735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57676 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       clean_lyrics  year  \\\n",
       "0      3243956  from a young child they were groomed a silver ...  2017   \n",
       "1       133218  fly fly away from troubles from pain from ever...  2013   \n",
       "2      4776446  night and day you are the one day and night wh...  1976   \n",
       "3      3018973  the word on the street is that you're nothing ...  2016   \n",
       "4      3506859  honey i know you wanted me to be a jerk i know...  2018   \n",
       "...        ...                                                ...   ...   \n",
       "57671  3510901  king of the ocean like nep making that girl so...  2017   \n",
       "57672  4233574  intro   you you were the one you you were the ...  2019   \n",
       "57673   365387  now i realize weâ€™ve been at this for some time...  2014   \n",
       "57674  3302658  brennan jackson back at it again    it's lit i...  2017   \n",
       "57675  1388972  there might be a question that you ask before ...  1987   \n",
       "\n",
       "      song_era      tag pred_bin pred_multi conf_bin_country  \\\n",
       "0        2010s      rap      rap       rock         0.190897   \n",
       "1        2010s     misc     rock       rock          0.40449   \n",
       "2        1970s       rb      pop         rb         0.647109   \n",
       "3        2010s     rock       rb         rb          0.12651   \n",
       "4        2010s  country      pop    country         0.457873   \n",
       "...        ...      ...      ...        ...              ...   \n",
       "57671    2010s      rap      rap        rap         0.028627   \n",
       "57672    2010s       rb       rb         rb         0.114652   \n",
       "57673    2010s     misc      rap        rap         0.109686   \n",
       "57674    2010s      rap      rap        rap         0.469893   \n",
       "57675    1980s      pop       rb         rb         0.524606   \n",
       "\n",
       "      conf_multi_country conf_bin_pop conf_multi_pop conf_bin_rap  \\\n",
       "0               0.149482     0.408375       0.398963     0.618757   \n",
       "1               0.369744     0.563257       0.412386     0.131492   \n",
       "2               0.279069     0.701033       0.591166     0.140559   \n",
       "3               0.019957     0.440449       0.295926      0.34544   \n",
       "4                0.56247     0.543757       0.419094     0.362932   \n",
       "...                  ...          ...            ...          ...   \n",
       "57671            0.00856     0.097584       0.771129     0.946513   \n",
       "57672           0.071239     0.232559       0.705958     0.554192   \n",
       "57673           0.067209     0.268143        0.67046      0.61364   \n",
       "57674           0.049385     0.356064       0.730913     0.811409   \n",
       "57675           0.191578     0.488127       0.600158     0.108111   \n",
       "\n",
       "      conf_multi_rap conf_bin_rb conf_multi_rb conf_bin_rock conf_multi_rock  \n",
       "0           0.546467    0.072935      0.036403      0.444018        0.606285  \n",
       "1            0.05283    0.541641      0.392051      0.788672        0.423378  \n",
       "2            0.02307    0.493494      0.730702      0.552208        0.399072  \n",
       "3           0.057912    0.540133      0.879046      0.454184        0.262347  \n",
       "4           0.078012    0.317433       0.09485      0.288224        0.371424  \n",
       "...              ...         ...           ...           ...             ...  \n",
       "57671       0.953579    0.181817      0.063754      0.060267        0.019171  \n",
       "57672       0.130881    0.578938      0.751298      0.236539        0.123574  \n",
       "57673       0.829115    0.214917      0.374229       0.46163        0.220678  \n",
       "57674       0.791271    0.295346       0.50523      0.109829        0.032338  \n",
       "57675       0.049851    0.616564      0.810046      0.292769        0.304735  \n",
       "\n",
       "[57676 rows x 17 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"train_tag_xg.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a77e70b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Œ Classification Report â€“ Binary Model (pred_bin)\n",
      "==============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.56      0.69      0.62      7676\n",
      "         pop       0.39      0.24      0.30     10000\n",
      "         rap       0.76      0.83      0.79     10000\n",
      "          rb       0.57      0.60      0.59     10000\n",
      "        rock       0.52      0.56      0.54     10000\n",
      "\n",
      "    accuracy                           0.58     47676\n",
      "   macro avg       0.56      0.58      0.57     47676\n",
      "weighted avg       0.56      0.58      0.56     47676\n",
      "\n",
      "\n",
      "==============================\n",
      "ðŸ“Œ Classification Report â€“ Multi-Class Model (pred_multi)\n",
      "==============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.73      0.64      0.68      7676\n",
      "         pop       0.32      0.29      0.31     10000\n",
      "         rap       0.89      0.72      0.79     10000\n",
      "          rb       0.57      0.75      0.65     10000\n",
      "        rock       0.55      0.59      0.57     10000\n",
      "\n",
      "    accuracy                           0.59     47676\n",
      "   macro avg       0.61      0.60      0.60     47676\n",
      "weighted avg       0.61      0.59      0.59     47676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def build_reports(df, true_col=\"tag\", pred_bin_col=\"pred_bin\", pred_multi_col=\"pred_multi\", ignore_class=\"misc\"):\n",
    "    # Remove misc from evaluation\n",
    "    df_eval = df[df[true_col] != ignore_class]\n",
    "\n",
    "    # Drop rows with missing predictions\n",
    "    df_eval = df_eval.dropna(subset=[true_col, pred_bin_col, pred_multi_col])\n",
    "\n",
    "    y_true = df_eval[true_col].astype(str)\n",
    "    y_pred_bin = df_eval[pred_bin_col].astype(str)\n",
    "    y_pred_multi = df_eval[pred_multi_col].astype(str)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"ðŸ“Œ Classification Report â€“ Binary Model (pred_bin)\")\n",
    "    print(\"==============================\")\n",
    "    print(classification_report(y_true, y_pred_bin))\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"ðŸ“Œ Classification Report â€“ Multi-Class Model (pred_multi)\")\n",
    "    print(\"==============================\")\n",
    "    print(classification_report(y_true, y_pred_multi))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Run it\n",
    "# ----------------------------\n",
    "build_reports(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "891c3ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: (47676,)\n",
      "y_pred_bin: (47676,)\n",
      "y_pred_multi: (47676,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ====== Labels ======\n",
    "labels = [\"country\", \"pop\", \"rap\", \"rb\", \"rock\"]\n",
    "\n",
    "# ====== True supports ======\n",
    "support = {\n",
    "    \"country\": 7676,\n",
    "    \"pop\": 10000,\n",
    "    \"rap\": 10000,\n",
    "    \"rb\": 10000,\n",
    "    \"rock\": 10000\n",
    "}\n",
    "\n",
    "# ====== Recalls from report ======\n",
    "recall_bin = {\n",
    "    \"country\": 0.69,\n",
    "    \"pop\": 0.24,\n",
    "    \"rap\": 0.83,\n",
    "    \"rb\": 0.60,\n",
    "    \"rock\": 0.56\n",
    "}\n",
    "\n",
    "recall_multi = {\n",
    "    \"country\": 0.64,\n",
    "    \"pop\": 0.29,\n",
    "    \"rap\": 0.72,\n",
    "    \"rb\": 0.75,\n",
    "    \"rock\": 0.59\n",
    "}\n",
    "\n",
    "# ====== Build y_true ======\n",
    "y_true = []\n",
    "for label in labels:\n",
    "    y_true += [label] * support[label]\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "\n",
    "# ====== Helper to generate prediction arrays ======\n",
    "def generate_preds(recalls):\n",
    "    y_pred = []\n",
    "\n",
    "    for label in labels:\n",
    "        n = support[label]\n",
    "        correct = int(round(n * recalls[label]))\n",
    "        incorrect = n - correct\n",
    "\n",
    "        # correct predictions\n",
    "        y_pred += [label] * correct\n",
    "\n",
    "        # distribute incorrect predictions across other classes\n",
    "        wrong_classes = [l for l in labels if l != label]\n",
    "        per_class = incorrect // 4\n",
    "        remainder = incorrect % 4\n",
    "\n",
    "        # base distribution\n",
    "        for w in wrong_classes:\n",
    "            y_pred += [w] * per_class\n",
    "\n",
    "        # assign remainders\n",
    "        for i in range(remainder):\n",
    "            y_pred.append(wrong_classes[i])\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "# ====== Build predictions ======\n",
    "y_pred_bin = generate_preds(recall_bin)\n",
    "y_pred_multi = generate_preds(recall_multi)\n",
    "\n",
    "# ====== Check counts ======\n",
    "print(\"y_true:\", y_true.shape)\n",
    "print(\"y_pred_bin:\", y_pred_bin.shape)\n",
    "print(\"y_pred_multi:\", y_pred_multi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1aad7b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_prf_bars\u001b[39m(y_true, y_pred, model_name=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def plot_prf_bars(y_true, y_pred, model_name=\"Model\"):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"label\": labels,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"f1\": f\n",
    "    })\n",
    "\n",
    "    df.set_index(\"label\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "    plt.title(f\"{model_name} â€“ Precision/Recall/F1\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e67f9027",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_prf_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBinary Logistic Model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m plot_prf_bars(y_true, y_pred_multi, \u001b[33m\"\u001b[39m\u001b[33mMulti-Class Logistic Model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mplot_prf_bars\u001b[39m\u001b[34m(y_true, y_pred, model_name)\u001b[39m\n\u001b[32m      6\u001b[39m p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, labels=labels)\n\u001b[32m      8\u001b[39m df = pd.DataFrame({\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: labels,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m: p,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m: r,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m: f\n\u001b[32m     13\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m plt.title(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m â€“ Precision/Recall/F1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/pandas/plotting/_core.py:947\u001b[39m, in \u001b[36mPlotAccessor.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     plot_backend = \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     x, y, kind, kwargs = \u001b[38;5;28mself\u001b[39m._get_call_args(\n\u001b[32m    950\u001b[39m         plot_backend.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m._parent, args, kwargs\n\u001b[32m    951\u001b[39m     )\n\u001b[32m    953\u001b[39m     kind = \u001b[38;5;28mself\u001b[39m._kind_aliases.get(kind, kind)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/pandas/plotting/_core.py:1944\u001b[39m, in \u001b[36m_get_plot_backend\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[32m-> \u001b[39m\u001b[32m1944\u001b[39m module = \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1945\u001b[39m _backends[backend_str] = module\n\u001b[32m   1946\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Understanding-Language-Change-in-Thai-Music/.venv/lib/python3.13/site-packages/pandas/plotting/_core.py:1874\u001b[39m, in \u001b[36m_load_backend\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m   1872\u001b[39m         module = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mpandas.plotting._matplotlib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   1875\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmatplotlib is required for plotting when the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1876\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mdefault backend \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m is selected.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1877\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[32m   1880\u001b[39m found_backend = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "plot_prf_bars(y_true, y_pred_bin, \"Binary Logistic Model\")\n",
    "plot_prf_bars(y_true, y_pred_multi, \"Multi-Class Logistic Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5e240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Understanding-Language-Change-in-Thai-Music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
